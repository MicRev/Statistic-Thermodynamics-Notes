## Entropy

In traditional thermodynamics, we define entropy as

$$
S = \int_0^{T^*} \frac{C_{p}}{T}dT
$$

which is not quite easy to calculate.

Statistic Thermodynamics allows us to calculate entropy ab initio.

### Seperating different contributions

We can seperate the entropy into contributions of different energies.

$$
S_{trans} = NK\ln q_{trans} - NK\ln N + NK + NK \left(\frac{\partial \ln q_{trans}}{\partial T} \right)
$$

whose last term is similar to that of $U$'s

$$
U_{trans} = NKT^2 \left(\frac{\partial \ln q_{\operatorname{trans}}}{\partial T} \right)
$$

so we have

$$
S_{trans} = NK\ln q_{trans} - NK\ln N + NK + \frac{U_{trans}}{T}
$$

similarly, 

$$
S_{rot} = NK\ln q_{rot} + \frac{U_{rot}}{T} \\
S_{vib} = NK\ln q_{vib} + \frac{U_{vib}}{T}
$$

### Translational

We are familiar that

$$
q_{trans} = \left(\frac{2\pi mkT}{h^2} \right)^{\frac{3}{2}}V
$$

which leads that the internal energy to be $\frac{3}{2}kT$, thus

$$
\begin{aligned}
 S_{trans} & = NK\ln\left(\frac{2\pi mkT}{h^2} \right)^{\frac{3}{2}}V - NK\ln N + NK + \frac{U_{trans}}{T} \\
 & = R\left[\left\{\left(\frac{2\pi mkT}{h^2} \right)^{\frac{3}{2}} V_m \right\} - \ln N + \frac{5}{2}\right]
\end{aligned}
$$

where $pV_m = RT$.

## Rotational Entropy

Suppose temperature is high enough compared to $KT$, the partition function is given by

$$
q_{rot} = \frac{T}{\sigma \theta_{rot}}
$$

we've discussed that in such situation $U_{rot} = NKT$, hence the entropy

$$
\begin{aligned}
S_{rot} & = NK\ln q_{rot} + \frac{U_{rot}}{T} \\
& = NK\ln \frac{T}{\sigma \theta_{rot}} + NK \\
& = NK(\ln \left\{\frac{T}{\sigma \theta_{rot}} \right\}+1)
\end{aligned}
$$

## Vibrational Entropy

Harmonic oscillator, partition function is given by

$$
q'_{vib} = \frac{1}{1-\exp (\frac{-\theta_{vib}}{T})}
$$ 

corresponding internal energy

$$
U'_{vib} = \frac{NK\theta_{vib}}{\exp (\frac{\theta_{vib}}{T}) - 1}
$$

thus entropy equals

$$
S_{vib} = NK\ln q'_{vib} + \frac{U'_{vib}}{T}
$$

for polyatomic molecules, calculate the entropy of each normal mode and add them together.

However, the case is often that $\theta_{vib} \gg T, q'_{vib} = 1, U'_{vib} = 0$. consequently, it is often reasonable to expect the contribution of vibration to entropy is 0 and that all particles are on the ground state.

## Electronic contribution

Usually only electron ground states are occupied, thus $q'_{elec} = g_0, U'_{elec} = 0$, and thus

$$
S_{elec} = Nklnq'_{elec} + \frac{U'_{elec}}{T} = Nk\ln g_0
$$

## Classical methods

In classical thermodynamics we use the integral to compute emtropy

$$
S = \int_0^{T^*} \frac{C_p (T)}{T}dT
$$

in low temperature, it is hard to measure the true value of heat capacity, but it is convenient that we suppose solid material under such temperature obeys *Debye Law*, which determines the heat capacity $C_p(T) = aT^3$, where the value of $a$ varies from different material.

In addition, phase transition should be considered.

$$
S_{pc} = \frac{\Delta H_{pc}}{T_{pc}}
$$

therefore, the full expression follows

$$
S(T^*) = \int_0^{T^*} \frac{C_p (T)}{T}dT + \sum_{phase~changes} \frac{\Delta H_{pc}}{T_{pc}}
$$

in most cases the entropy calculated by statistical themodynamics and the one measured by thermochemistry correspond well, but in a number of cases, the calculated one exceeds. 

The reason is that some precise phase transitions are not considered. Take $CO$ as an example, the molecules are expected to **be oriented randomly** and thus the entropy is relatively large.

However, in low temperature, especially in absolute zero, the molecules arrange in a **perfectly ordered** way, whose entropy is 0. The transition between the two phases will happen only in low temperature, which could not be easily measured. Consequently, ignoring such phase transition, the measured entropy will be lower than actual value.

For simple molecules like $CO$, we estimate the lost entropy by 

$$
S = k\ln \Omega = k\ln 2^N = kN\ln 2
$$

when 1 mol, $S_m = R\ln 2$
